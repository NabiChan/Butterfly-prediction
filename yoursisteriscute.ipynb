{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fc055ce-25db-4a15-a6be-234c6dd3ed02",
   "metadata": {},
   "source": [
    "# pytorch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a975bed-0bfc-4962-99b1-fab08eeedbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77136374-9a89-4db2-87ce-0b23e02d6906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename    6499\n",
       "label         75\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df= pd.read_csv(\"Training_set.csv\")\n",
    "test_df= pd.read_csv(\"Testing_set.csv\")\n",
    "train_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e331cc-28ce-463d-80ea-5378604f2b6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_img= r\"/Users/nguyenthephong/Desktop/Okay this is ML serious/project for practicing/butterfly ah ah folder/train\"\n",
    "test_img=r\"/Users/nguyenthephong/Desktop/Okay this is ML serious/project for practicing/butterfly ah ah folder/test\"\n",
    "\n",
    "#method for get the class for the train path\n",
    "def set_class(path,df):\n",
    "    for images_name in os.listdir(path):\n",
    "        for index,row in df.iterrows():\n",
    "            if row[\"filename\"]==images_name:\n",
    "                class_img= row[\"label\"]\n",
    "                if not os.path.exists(os.path.join(path,class_img)):\n",
    "                    os.makedirs(os.path.join(path,class_img))\n",
    "                shutil.move(os.path.join(path,images_name),os.path.join(path,class_img, images_name))\n",
    "\n",
    "# set_class(train_img,train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e89b1cd1-9f64-4dde-af7b-e5f2b8cacca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65aa4887-38be-459f-bf85-b08f3bac9d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform =T.Compose([T.Resize(512),\n",
    "                      T.ToTensor(),\n",
    "                      T.RandomHorizontalFlip(p=0.5),\n",
    "                      T.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))])\n",
    "\n",
    "test_transform =T.Compose([T.Resize(512),\n",
    "                      T.ToTensor(),\n",
    "                      T.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4341a65d-066d-4fa7-bd43-f709fbda95b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 512])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path= ImageFolder(root=train_img,transform=train_transform)\n",
    "train_path[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81f4fc76-ecc1-43bd-84dd-5be51ab602d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dataloader.DataLoader(train_path, shuffle=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e693d589-02b2-401c-8d09-33ae8b925179",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BruhNN(nn.Module):\n",
    "    def __init__(self,color_channel,classes):\n",
    "        super(BruhNN, self).__init__()\n",
    "        self.Convlayer= nn.Sequential(\n",
    "            nn.Conv2d(color_channel,256,kernel_size=3),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(256,128,kernel_size=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(128,64,kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(64,128,kernel_size=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128,256,kernel_size=1)\n",
    "        )\n",
    "        self.flattenlayer= nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3*256*256,512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512,1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024,classes)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.flattenlayer(self.Convlayer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aa1aa7f-cf0f-4143-a58f-8908a8e06059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101422347"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= BruhNN(3,75)\n",
    "param=0\n",
    "for paras in model.parameters():\n",
    "    param += paras.flatten().shape[0]\n",
    "\n",
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8727a44c-fea4-4b45-bfac-cccebc0b5aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.AdamW(model.parameters(),lr=0.01)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "wrong_stored=[]\n",
    "model.to(device)\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for i,(inputs,labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted=model(inputs.to(device))\n",
    "        wrong=loss(predicted,labels.to(device))\n",
    "        wrong.backward()\n",
    "        optimizer.step()\n",
    "        wrong_stored.append(wrong)\n",
    "\n",
    "wrong_stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb1e14-3795-4627-af38-28a10b976eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
